{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import roman as roman\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier, plot_importance, XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import roman\n",
    "from model import D1ffic00ltLinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train-2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "answer = list(set(data[data.TargetClass == 0].SpType.unique()) & set(data[data.TargetClass == 1].SpType.unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['G8IVp',\n 'G6V',\n 'B2V+...',\n 'A3II/III',\n 'A3III + K1:',\n 'G3IV/V',\n 'B7Ib/II',\n 'B7Iab...',\n 'B3III',\n 'G9IV',\n 'G6/8wF8IV/V',\n 'G4V:p',\n 'B8II',\n 'B9:Vn...',\n 'A8III',\n 'B9V+...',\n 'F0III:',\n 'B2III-IV',\n 'F0IIw...',\n 'G8IV',\n 'K0VCN...',\n 'K0V',\n 'B6/B7II',\n 'B1.5III-IVn',\n 'K7V',\n 'G3/G5Vw',\n 'B0Ib/II',\n 'G6IV/V',\n 'O9.5Ia SB:',\n 'A3II/IIIm..',\n 'A(V) + G5III',\n 'B9IIp...',\n 'B7II',\n 'K3III',\n 'K0IV:',\n 'F6/F7V',\n 'F4IIIvar',\n 'B5Ia',\n 'G6IV',\n 'K1IV/V',\n 'G9III-IV',\n 'B7/B8II/III',\n 'F0/F2IVm...',\n 'K1IV...',\n 'G7IV',\n 'B8Ia-Iab',\n 'A4V comp SB',\n 'B2IV-Ve',\n 'G8III/IV',\n 'K1III-IV',\n 'F8III/IV',\n 'K1IV',\n 'F3V:+...',\n 'F3IVp...',\n 'B0IVpe',\n 'B4II/III',\n 'B6II/III',\n 'B5Vn...',\n 'K3III+A0IV/V',\n 'F9III',\n 'G8/K0IV/V',\n 'A2V+...',\n 'A6III',\n 'A2/A3III',\n 'G3V',\n 'B2.5V',\n 'G5V',\n 'K0:III+...',\n 'K0IVw...',\n 'K1IVCN...',\n 'A2II/III',\n 'G8V',\n 'B6III',\n 'G5III-IV',\n 'K0IV/VCNIII',\n 'G6/G8III/IV',\n 'A3Vs',\n 'K1/2III: +F',\n 'A4/A5III:',\n 'B7Ib',\n 'B4II',\n 'G9V',\n 'A6:III:+...',\n 'K0/K1IVwp..',\n 'K2/K3V',\n 'K3V',\n 'G8IV...',\n 'K1/K2V',\n 'B0.5IVn',\n 'K3IV/V',\n 'B3Vn...']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data = data[~data.SpType.isin(answer)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "color_index = lambda x: 4600 * ((1 / (0.92 * x + 1.7)) + (1 / (0.92 * x + 0.62)))\n",
    "round_ = lambda x: round(x, 1)\n",
    "def transform_type2(x):\n",
    "    x1 = x\n",
    "    x1 = x1.replace('I', '')\n",
    "    x1 = x1.replace('V', '')\n",
    "    lst = list(set(x1))\n",
    "    for i in lst:\n",
    "        x = x.replace(i, ' ')\n",
    "    x = x.split()[-1]\n",
    "    return roman.fromRoman(x) * 1000\n",
    "transform_type = lambda x: 1 if \"V\" in x or \"VI\" in x or \"VII\" in x else -1\n",
    "# avag ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "Ms = 3.86 * 10 ** 33\n",
    "data[\"temp\"] = data[\"B-V\"].apply(color_index)\n",
    "# data[\"R\"] = np.sqrt(data.Vmag) / np.power(data.temp / 5778, 2)\n",
    "# data[\"M\"] = data.Vmag + 5 - (5 * np.log(data.Plx))\n",
    "# data[\"L\"] = np.power(data.R, 2) * np.power(data.temp / 5778, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# data.M.min()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       Vmag        Plx     e_Plx       B-V SpType       Amag  TargetClass  \\\n1  4.334196   2.198947  0.593309  1.153210   G2Ib  13.043324            0   \n2  7.873019  11.750465  0.616568  0.589166    F5V  17.736492            1   \n3  8.110014   2.143815  0.848508  1.322107  K2III  15.592469            0   \n4  8.025193   4.165622  0.899296  1.141646  K5III  16.379680            0   \n5  2.899130  11.110086  0.701719  1.095357  M0III  14.370388            0   \n\n          temp  \n1  4402.632871  \n2  6010.288989  \n3  4082.305608  \n4  4426.508743  \n5  4524.866088  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vmag</th>\n      <th>Plx</th>\n      <th>e_Plx</th>\n      <th>B-V</th>\n      <th>SpType</th>\n      <th>Amag</th>\n      <th>TargetClass</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4.334196</td>\n      <td>2.198947</td>\n      <td>0.593309</td>\n      <td>1.153210</td>\n      <td>G2Ib</td>\n      <td>13.043324</td>\n      <td>0</td>\n      <td>4402.632871</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.873019</td>\n      <td>11.750465</td>\n      <td>0.616568</td>\n      <td>0.589166</td>\n      <td>F5V</td>\n      <td>17.736492</td>\n      <td>1</td>\n      <td>6010.288989</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.110014</td>\n      <td>2.143815</td>\n      <td>0.848508</td>\n      <td>1.322107</td>\n      <td>K2III</td>\n      <td>15.592469</td>\n      <td>0</td>\n      <td>4082.305608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.025193</td>\n      <td>4.165622</td>\n      <td>0.899296</td>\n      <td>1.141646</td>\n      <td>K5III</td>\n      <td>16.379680</td>\n      <td>0</td>\n      <td>4426.508743</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.899130</td>\n      <td>11.110086</td>\n      <td>0.701719</td>\n      <td>1.095357</td>\n      <td>M0III</td>\n      <td>14.370388</td>\n      <td>0</td>\n      <td>4524.866088</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# data[\"spt2\"] = data.SpType.apply(transform_type2)\n",
    "data.SpType = data.SpType.apply(transform_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       Vmag        Plx     e_Plx       B-V  SpType       Amag  TargetClass  \\\n1  4.334196   2.198947  0.593309  1.153210      -1  13.043324            0   \n2  7.873019  11.750465  0.616568  0.589166       1  17.736492            1   \n3  8.110014   2.143815  0.848508  1.322107      -1  15.592469            0   \n4  8.025193   4.165622  0.899296  1.141646      -1  16.379680            0   \n5  2.899130  11.110086  0.701719  1.095357      -1  14.370388            0   \n\n          temp  \n1  4402.632871  \n2  6010.288989  \n3  4082.305608  \n4  4426.508743  \n5  4524.866088  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vmag</th>\n      <th>Plx</th>\n      <th>e_Plx</th>\n      <th>B-V</th>\n      <th>SpType</th>\n      <th>Amag</th>\n      <th>TargetClass</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4.334196</td>\n      <td>2.198947</td>\n      <td>0.593309</td>\n      <td>1.153210</td>\n      <td>-1</td>\n      <td>13.043324</td>\n      <td>0</td>\n      <td>4402.632871</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.873019</td>\n      <td>11.750465</td>\n      <td>0.616568</td>\n      <td>0.589166</td>\n      <td>1</td>\n      <td>17.736492</td>\n      <td>1</td>\n      <td>6010.288989</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.110014</td>\n      <td>2.143815</td>\n      <td>0.848508</td>\n      <td>1.322107</td>\n      <td>-1</td>\n      <td>15.592469</td>\n      <td>0</td>\n      <td>4082.305608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.025193</td>\n      <td>4.165622</td>\n      <td>0.899296</td>\n      <td>1.141646</td>\n      <td>-1</td>\n      <td>16.379680</td>\n      <td>0</td>\n      <td>4426.508743</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.899130</td>\n      <td>11.110086</td>\n      <td>0.701719</td>\n      <td>1.095357</td>\n      <td>-1</td>\n      <td>14.370388</td>\n      <td>0</td>\n      <td>4524.866088</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data = data[data.Plx + data.e_Plx > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# plt.boxplot(data.Vmag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# data = data[(data.Vmag > 4) & (data.Vmag < 11)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# plt.boxplot(data[\"B-V\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# data = data[data[\"B-V\"] < 23]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# plt.boxplot(data.Amag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# data = data[(data.Amag < 22) & (data.Amag > 10)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# data.Amag = data.Amag.apply(round_)\n",
    "# data.Vmag = data.Vmag.apply(round_)\n",
    "# data.Plx = data.Plx.apply(round_)\n",
    "# data.e_Plx = data.e_Plx.apply(round_)\n",
    "# data[\"B-V\"] = data[\"B-V\"].apply(round_)\n",
    "# data.temp = data.temp.apply(round_)\n",
    "# model[\"BVtype\"] = round(model[\"B-V\"] * model.SpType)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# data = data.drop( [\"e_Plx\"], axis=1)\n",
    "data[:] = MinMaxScaler().fit_transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "       Vmag       Plx     e_Plx       B-V  SpType      Amag  TargetClass  \\\n1  0.423018  0.044991  0.042741  0.555190     0.0  0.350098          0.0   \n2  0.705768  0.153779  0.047013  0.354782     1.0  0.570943          1.0   \n3  0.724704  0.044363  0.089611  0.615200     0.0  0.470053          0.0   \n4  0.717927  0.067391  0.098939  0.551081     0.0  0.507096          0.0   \n5  0.308357  0.146486  0.062652  0.534635     0.0  0.412545          0.0   \n\n       temp  \n1  0.081891  \n2  0.164016  \n3  0.065528  \n4  0.083111  \n5  0.088135  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vmag</th>\n      <th>Plx</th>\n      <th>e_Plx</th>\n      <th>B-V</th>\n      <th>SpType</th>\n      <th>Amag</th>\n      <th>TargetClass</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.423018</td>\n      <td>0.044991</td>\n      <td>0.042741</td>\n      <td>0.555190</td>\n      <td>0.0</td>\n      <td>0.350098</td>\n      <td>0.0</td>\n      <td>0.081891</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.705768</td>\n      <td>0.153779</td>\n      <td>0.047013</td>\n      <td>0.354782</td>\n      <td>1.0</td>\n      <td>0.570943</td>\n      <td>1.0</td>\n      <td>0.164016</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.724704</td>\n      <td>0.044363</td>\n      <td>0.089611</td>\n      <td>0.615200</td>\n      <td>0.0</td>\n      <td>0.470053</td>\n      <td>0.0</td>\n      <td>0.065528</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.717927</td>\n      <td>0.067391</td>\n      <td>0.098939</td>\n      <td>0.551081</td>\n      <td>0.0</td>\n      <td>0.507096</td>\n      <td>0.0</td>\n      <td>0.083111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.308357</td>\n      <td>0.146486</td>\n      <td>0.062652</td>\n      <td>0.534635</td>\n      <td>0.0</td>\n      <td>0.412545</td>\n      <td>0.0</td>\n      <td>0.088135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAJDCAYAAADtp9X3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyGUlEQVR4nO3de7xsdV3/8ddbFNBCASVEAUVFUUJBkTTNFNHwkpCpQP0Mf6mnMi+ZGpIGRGpe6mdpWh6VxEvgLZXUVMRLhhLnqASIKIiaIF4QxTu3/fn9MevkeNxn7ZmzZ83stXw9eazHnllrzcxnzjns/dnv7/e7JlWFJEnSUN1g0QVIkiR1yWZHkiQNms2OJEkaNJsdSZI0aDY7kiRp0Gx2JEnSoNnsSJKkmUpyUpJvJDl/C8eT5GVJLk5ybpK7jx07OslFzXb0LOqx2ZEkSbP2OuDQluMPAfZutnXAPwIk2Rk4HvgV4CDg+CQ7rbYYmx1JkjRTVfUfwJUtpxwGvL5GzgJ2TLIb8BvA6VV1ZVV9Gzid9qZpIjdc7RNM4torLhn0ZZpPOPC5iy6hU895xo6LLqFTn/+bSxddQme2veH1iy6hUzff8/uLLqFTZ3721osuoVP7/MJViy6hU3f5wnsyr9ea98/ZbXe5/R8wSmQ2WV9V66d4ilsDXxm7f2mzb0v7V2UuzY4kSRqOprGZprlZKJsdSZL6bql3Ke5lwB5j93dv9l0G3H+z/R9Z7Ys5Z0eSJM3bacDvNauy7gVcVVWXA+8HHpxkp2Zi8oObfatisiNJkmYqySmMEppbJLmU0QqrGwFU1T8B7wUeClwM/BD4v82xK5P8FbCheaoTq6ptovNEbHYkSeq7Wlp0BT+lqo5a4XgBf7yFYycBJ82yHoexJEnSoJnsSJLUd0trK9lZa0x2JEnSoJnsSJLUc7XG5uysNSY7kiRp0Ex2JEnqO+fstDLZkSRJg2ayI0lS3zlnp5XJjiRJGjSTHUmS+q5/HwQ6VyY7kiRp0Ex2JEnqO+fstDLZkSRJg2ayI0lS33mdnVYmO5IkadBsdiRJ0qA5jCVJUs/5QaDtJmp2kuy8zO7vVdW1M65HkiRppiZNdj4F7AF8GwiwI/C1JF8HnlhVn+ymPEmStCInKLeadM7O6cBDq+oWVXVz4CHAu4EnAa/sqjhJkqTVmrTZuVdVvX/Tnar6AHDvqjoL2K6TyiRJ0mRqab5bz0w6jHV5kmOAU5v7RwBfT7IN0L93LUmSfm5M2uz8DnA88M7m/pnNvm2Ax8y+LEmSNDE/CLTVRM1OVV0BPGULhy+eXTmSJEmzNenS812APwP2BbbftL+qDu6oLkmSNKkezqOZp0knKL8JuBDYC/hL4EvAho5qkiRJmplJ5+zcvKpem+RpVfVR4KNJbHYkSVoLvM5Oq0mbnU1XSr48ycOArwLLXVVZkiRpTZl0GOt5SW4GPAN4JvAa4OltD0iyLsnGJBtf8/pTVlmmJEnaIq+z02rS1Vjvbm5eBTxgwsesB9YDXHvFJbVV1UmSJK3SpKux9mK09Py244+pqkd0U5YkSZqYc3ZaTTpn553Aa4F/wysmS5KkHpm02flxVb2s00okSZI6MGmz8/dJjgc+AFy9aWdVfaqTqiRJ0sSq/LiINpM2O/sBjwUO5ifDWNXclyRJWrMmbXYeDdyuqq7pshhJkrQVergcfJ4mvc7O+cCOHdYhSZLUiUmTnR2BC5uPiBifs+PSc0mSFs2l561am50krwBOAY6fTzmSJEmztVKy83ngJcBuwFuAU6rq051XJUmSJuecnVatc3aq6u+r6t7ArwPfAk5KcmGS45PccS4VSpIkrcKkn431ZeBFwIuSHACcBBwHbNNhbZIkaRJLXmenzUSrsZLcMMlvJnkT8O/A54BHdlqZJEnSDKw0QflBwFHAQ4GzgVOBdVX1gznUJkmSJuGcnVYrDWMdC/wL8Iyq+vYc6pEkSZqp1manqvw4CEmS1jqvs9Nq0isoS5Ik9dKkV1CWJElrlXN2WpnsSJKkQbPZkSRJg+YwliRJfecE5VYmO5IkadBMdiRJ6juTnVYmO5IkadBMdiRJ6rkqPwi0jcmOJEkaNJMdSZL6zjk7rUx2JEnSoJnsSJLUd35cRCuTHUmSNGgmO5Ik9Z1zdlqZ7EiSpJlKcmiSzyW5OMmzlzn+0iTnNNvnk3xn7Nj1Y8dOm0U9c0l2TjjwufN4mYU5YePzFl1Cp06523GLLqFTN1naYdEldOaBB1226BI6td399l10CZ3a44WXL7qETu129x8suoThWENzdpJsA7wCeBBwKbAhyWlVdcGmc6rq6WPnPwU4YOwpflRV+8+yJpMdSZI0SwcBF1fVJVV1DXAqcFjL+UcBp3RZkM2OJEl9t7Q01y3JuiQbx7Z1Y9XcGvjK2P1Lm30/I8ltgL2AD43t3r55zrOSHD6LPx4nKEuSpKlU1Xpg/Qye6kjgbfXTn3dxm6q6LMntgA8lOa+qvrCaF7HZkSSp79bQnB3gMmCPsfu7N/uWcyTwx+M7quqy5uslST7CaD7Pqpodh7EkSdIsbQD2TrJXkm0ZNTQ/s6oqyT7ATsAnxvbtlGS75vYtgPsAF2z+2GmZ7EiSpJmpquuSPBl4P7ANcFJVfSbJicDGqtrU+BwJnFpVNfbwOwOvSrLEKJB54fgqrq1lsyNJUt+tsYsKVtV7gfdutu+4ze6fsMzjPg7sN+t6HMaSJEmDZrIjSVLfrbFkZ60x2ZEkSYNmsiNJUt+traXna47JjiRJGjSTHUmS+s45O61MdiRJ0qCZ7EiS1HfO2WllsiNJkgbNZEeSpL5zzk4rkx1JkjRoJjuSJPWdc3ZamexIkqRBM9mRJKnvnLPTymRHkiQNms2OJEkaNIexJEnqO4exWpnsSJKkQTPZkSSp76oWXcGaZrIjSZIGzWRHkqS+c85Oq4mTnSS/tMy+O822HEmSpNmaZhjrY0kes+lOkmcA75h9SZIkaSpLS/PdemaaYaz7A+uTPBrYFfgscFAXRUmSJM3KxM1OVV2e5H3AscAS8Oyq+n5nlUmSpMn4QaCtJm52knwQ+Crwy8AewGuT/EdVPbOr4iRJklZrmjk7/1BVv1dV36mq84BfBa7a0slJ1iXZmGTjp7938aoLlSRJW+CcnVYTNztV9c7N7l9XVX/Vcv76qjqwqg48YIc7rKJESZKkrbfiMFaS7wEFpNm16TKNAaqqbtpRbZIkaRJeQbnVis1OVe0wj0IkSZK6MEmysz3wh8AdgHOBk6rquq4LkyRJE+rhPJp5mmTOzsnAgcB5wEOBv+20IkmSpBmaZOn5XapqP4AkrwXO7rYkSZKk2Zmk2bl2042qui5J27mSJGneHMZqNUmzc7ck321uB7hxc9/VWJIkac2bZDXWNvMoRJIkbSU/LqLVNFdQliRJ6p1pPvVckiStQbXkRQXbmOxIkqRBM9mRJKnvXI3VymRHkiQNmsmOJEl952qsViY7kiRp0Ex2JEnqO1djtTLZkSRJg2ayI0lS37kaq5XJjiRJGjSTHUmS+s5kp5XJjiRJGjSbHUmSNGgOY0mS1Hfl0vM2JjuSJGnQTHYkSeo7Jyi3MtmRJEmDZrIjSVLf+XERrUx2JEnSoJnsSJLUd+WcnTYmO5IkadBMdiRJ6jvn7LQy2ZEkSYM2l2TnOc/YcR4vszCn3O24RZfQqaP++8RFl9Cpzx74tEWX0JmvbNhh0SV0atdvXrDoEjr1letvtegSOrXdhusWXUKndprja5XX2WllsiNJkmYqyaFJPpfk4iTPXub445J8M8k5zfaEsWNHJ7mo2Y6eRT3O2ZEkqe/W0JydJNsArwAeBFwKbEhyWlVtHsW+uaqevNljdwaOBw4ECvhk89hvr6Ymkx1JkjRLBwEXV9UlVXUNcCpw2ISP/Q3g9Kq6smlwTgcOXW1BNjuSJPVdLc11S7Iuycaxbd1YNbcGvjJ2/9Jm3+Z+O8m5Sd6WZI8pHzsVh7EkSdJUqmo9sH4VT/FvwClVdXWSPwBOBg6eSXHLMNmRJEmzdBmwx9j93Zt9/6uqvlVVVzd3XwPcY9LHbg2bHUmS+m6p5ru12wDsnWSvJNsCRwKnjZ+QZLexu48APtvcfj/w4CQ7JdkJeHCzb1UcxpIkSTNTVdcleTKjJmUb4KSq+kySE4GNVXUa8NQkjwCuA64EHtc89sokf8WoYQI4saquXG1NNjuSJPXdGruoYFW9F3jvZvuOG7t9LHDsFh57EnDSLOtxGEuSJA2ayY4kSX23hi4quBaZ7EiSpEEz2ZEkqe9qbc3ZWWtMdiRJ0qCZ7EiS1HfO2WllsiNJkgbNZEeSpJ6rNXadnbXGZEeSJA2ayY4kSX3nnJ1WJjuSJGnQTHYkSeo7k51WJjuSJGnQbHYkSdKgTdzsJLnLMvvuP8tiJEnSVqil+W49M02y85Ykx2TkxkleDvx1V4VJkiTNwjTNzq8AewAfBzYAXwXu00VRkiRpCks1361npml2rgV+BNwY2B74YlUPsyxJkvRzZZpmZwOjZueewK8BRyV5aydVSZKkidVSzXXrm2mus/P4qtrY3L4cOCzJYzuoSZIkaWZWbHaS7NzcvGTs9ibvmX1JkiRpKj1MW+ZpkmTnk0ABWeZYAbebaUWSJEkztGKzU1V7zaMQSZK0lZZcL9RmxQnKSX4pyd8leXeSFyS56TwKkyRJmoVJVmO9HvgB8HJgB+BlkzxxknVJNibZeNKZF6yiREmS1Mrr7LSaZM7OblX1nOb2+5N8apInrqr1wHqAH778Sf37k5EkSYMw0dLzJDvxkwnK24zfr6orO6pNkiRNoodpyzxN0uzcjNGKrPHVWJvSHVdjSZKkNW2S1Vi3neSJkuxbVZ9ZdUWSJGkqVSY7bab5uIiVvGGGzyVJkjQTs2x2lrvooCRJ0kJN89lYKzFDkyRpEZyg3GqWyY4kSdKaM3GykyTA7wK3q6oTk+wJ3LKqzm5OuaaLAiVJ0gpMdlpNk+y8Erg3cFRz/3vAKzYdrKp7zbAuSZKkmZhmzs6vVNXdk3waoKq+nWTbjuqSJEkTKpOdVtMkO9cm2YZmInKSXQA/ZlWSJK1p0yQ7LwPeAfxSkucDjwKe20lVkiRpciY7rSZudqrqTUk+CTyQ0TV1Dq+qz3ZWmSRJ0gxMdZ2dqroQuLCjWiRJ0tZwUkkrr7MjSZIGbZZXUJYkSQvgaqx2JjuSJGnQTHYkSeo7k51WJjuSJGnQTHYkSeo7V2O1MtmRJEmDZrMjSZIGzWEsSZJ6zqXn7Ux2JEnSoJnsSJLUd05QbmWyI0mSBs1kR5KknnPOTjuTHUmSNGgmO5Ik9Z1zdlqZ7EiSpEEz2ZEkqefKZKeVyY4kSRq0uSQ7n/+bS+fxMgtzk6UdFl1Cpz574NMWXUKn7rzx7xddQmcOvtsTF11Cp55+4a0WXUKnHnPlRxddQqfuvcs+iy6hUx+b54uZ7LQy2ZEkSYPmnB1JknrOOTvtTHYkSdJMJTk0yeeSXJzk2csc/9MkFyQ5N8kZSW4zduz6JOc022mzqMdkR5KkvltDyU6SbYBXAA8CLgU2JDmtqi4YO+3TwIFV9cMkfwS8GDiiOfajqtp/ljWZ7EiSpFk6CLi4qi6pqmuAU4HDxk+oqg9X1Q+bu2cBu3dZkM2OJEmaSpJ1STaObevGDt8a+MrY/UubfVvyeODfx+5v3zznWUkOn0W9DmNJktRz856gXFXrgfWrfZ4k/wc4EPj1sd23qarLktwO+FCS86rqC6t5HZMdSZI0S5cBe4zd373Z91OSHAI8B3hEVV29aX9VXdZ8vQT4CHDAaguy2ZEkqedqab7bCjYAeyfZK8m2wJHAT62qSnIA8CpGjc43xvbvlGS75vYtgPsA4xObt4rDWJIkaWaq6rokTwbeD2wDnFRVn0lyIrCxqk4DXgL8IvDWJAD/U1WPAO4MvCrJEqNA5oWbreLaKjY7kiT13Fq7qGBVvRd472b7jhu7fcgWHvdxYL9Z1+MwliRJGjSTHUmS+q6y6ArWNJMdSZI0aCY7kiT13Fqbs7PWmOxIkqRBM9mRJKnnask5O21MdiRJ0qCZ7EiS1HPO2WlnsiNJkgbNZEeSpJ4rr7PTymRHkiQNms2OJEkaNIexJEnqOScotzPZkSRJg2ayI0lSz3lRwXYmO5IkadBWbHaSPCvJ7vMoRpIkTa9qvlvfTJLs3Ar4RJKPJXlSkl26LkqSJGlWVmx2qurpwJ7Ac4H9gHOTvC/J0Ul26LpASZLUrpYy161vJpqzUyMfrao/AnYHXgr8CfD1DmuTJElatalWYyXZDzgSOAK4Aji2i6IkSdLk+pi2zNOKzU6SvRk1OEcC1wOnAg+uqks6rk2SJGnVJhnGeh+wHXBEVd21ql4wSaOTZF2SjUk2vv37X151oZIkaXmuxmq3YrJTVbfffF+ST1XV3Vd43HpgPcA5t3lED/9oJEnSEGztFZQdHJQkaY1wzk67rb2C8ntmWoUkSVJHtjbZ+bskqerjyJ0kScNSZbLTZpKPi7hXko8k+dckByQ5Hzgf+HqSQ7svUZIkaetNkuz8A/DnwM2ADwEPqaqzkuwDnMJotZYkSVqQWlp0BWvbJHN2blhVH6iqtwJfq6qzAKrqwm5LkyRJWr1Jmp3xfvFHmx1zzo4kSVrTJhnGuluS7zJabn7j5jbN/e07q0ySJE1kyQnKrSa5qOA28yhEkiSpC1u79FySJK0RLj1vt7UXFZQkSeoFkx1JknrOj4toZ7IjSZIGzWRHkqSe88Ob2pnsSJKkQTPZkSSp55yz085kR5IkDZrJjiRJPecVlNuZ7EiSpEEz2ZEkqee8gnI7kx1JkjRoJjuSJPWc19lpZ7IjSZIGzWZHkiQNmsNYkiT1nEvP25nsSJKkQTPZkSSp51x63s5kR5IkDZrJjiRJPefS83YmO5IkadBMdiRJ6jlXY7Uz2ZEkSYM2l2Rn2xteP4+XWZgHHnTZokvo1Fc27LDoEjp18N2euOgSOvOh/371okvo1I9PfOqiS+jUd/d8yKJL6NSNHvfniy5hMFyN1c5kR5IkDZpzdiRJ6jnn7LQz2ZEkSYNmsiNJUs95mZ12JjuSJGmmkhya5HNJLk7y7GWOb5fkzc3x/0py27Fjxzb7P5fkN2ZRj8mOJEk9t5bm7CTZBngF8CDgUmBDktOq6oKx0x4PfLuq7pDkSOBFwBFJ7gIcCewL3Ar4YJI7VtWqlnWb7EiSpFk6CLi4qi6pqmuAU4HDNjvnMODk5vbbgAcmSbP/1Kq6uqq+CFzcPN+q2OxIkqSpJFmXZOPYtm7s8K2Br4zdv7TZx3LnVNV1wFXAzSd87NQcxpIkqefmfVHBqloPrJ/ri66CyY4kSZqly4A9xu7v3uxb9pwkNwRuBnxrwsdOzWZHkqSeW5rztoINwN5J9kqyLaMJx6dtds5pwNHN7UcBH6qqavYf2azW2gvYGzh7mj+L5TiMJUmSZqaqrkvyZOD9wDbASVX1mSQnAhur6jTgtcAbklwMXMmoIaI57y3ABcB1wB+vdiUW2OxIktR7xdpZeg5QVe8F3rvZvuPGbv8YePQWHvt84PmzrMdhLEmSNGgmO5Ik9dySnxfRymRHkiQNmsmOJEk9t7TG5uysNSY7kiRp0Ex2JEnqubW2GmutmTjZSXKTJH+R5NXN/b2TPLy70iRJklZvmmGsfwauBu7d3L8MeN7MK5IkSVNZY1dQXnOmaXZuX1UvBq4FqKofgrmZJEla26aZs3NNkhsDBZDk9oySHkmStEDO2Wk3TbNzPPA+YI8kbwLuAzyui6IkSZJmZeJmp6pOT/Ip4F6Mhq+eVlVXdFaZJEnSDEy79PzXgfsyGsq6EfCOmVckSZKm0sdJw/M0zdLzVwJ/CJwHnA/8QZJXdFWYJEnSLEyT7BwM3LmqNk1QPhn4TCdVSZKkiZnstJtm6fnFwJ5j9/do9kmSJK1Z0yQ7OwCfTXI2ozk7BwEbk5wGUFWP6KA+SZK0Apeet5um2TmusyokSZI6Mk2zc1fgjVX17a6KkSRJ01sy2Gk1zZydXYENSd6S5NAk/tFKkqQ1b+Jmp6qeC+wNvJbRlZMvSvKC5mMjfkaSdUk2Jtn4lu/+z0yKlSRJP2uJzHXrm2mSHZpl519rtuuAnYC3JXnxMueur6oDq+rAx9x0z80PS5IkzcWKzU6SJzdfn5bkk8CLgTOB/arqj4B7AL/daZWSJGmLas5b30wyQfn3gX8AdgYeWVVfHj9YVUtJHt5FcZIkSas1zQeBHt9y7LOzKUeSJE3LKyi3m6TZuWuS7y6zP4ym8dx0xjVJkiTNzCTNznlVdUDnlUiSpK2y5NVgWk21GkuSJKlvJml23tp5FZIkSR1ZsdmpqhcAJLldkn9LckWSbyR5V5LbdV+iJElq49LzdtMMY/0L8BbglsCtGCU+p3RRlCRJ0qxM0+zcpKreUFXXNdsbge27KkySJE1mac5b30zzqef/nuTZwKmMUqwjgPcm2Rmgqq7soD5JkqRVmabZeUzzdV3zddM6tyMZNT/O35EkaQGWXHneasVmJ8k9ga9U1V7N/aMZfRbWl4ATTHQkSdJaNsmcnVcB1wAkuR/w18DJwFXA+u5KkyRJk1gic936ZpJhrG3G0psjgPVV9Xbg7UnO6awySZKkGZgk2dkmyaam6IHAh8aOTTPnR5IkdcDr7LSbpFk5BfhokiuAHwEfA0hyB0ZDWZIkSWvWis1OVT0/yRnAbsAHqmpTU3cD4CldFidJklbmaqx2Ew1DVdVZy+z7/OzLkSRJmi3n3EiS1HN9vKrxPE3zcRGSJEm9Y7IjSVLP9XGF1DyZ7EiSpEGz2ZEkSYPmMJYkST3n0vN2JjuSJGnQTHYkSeo5l563M9mRJEmDZrIjSVLPmey0M9mRJEmDZrIjSVLPlauxWpnsSJKkQZtLsnPzPb8/j5dZmO3ut++iS+jUrt+8YNEldOrpF95q0SV05scnPnXRJXRq++NetugSOnXmvscsuoRO3eN/hv3v80Yve/fcXss5O+1MdiRJ0qA5Z0eSpJ4z2WlnsiNJkgbNZEeSpJ6rRRewxpnsSJKkQbPZkSSp55Yy3201kuyc5PQkFzVfd1rmnP2TfCLJZ5Kcm+SIsWOvS/LFJOc02/4rvabNjiRJmqdnA2dU1d7AGc39zf0Q+L2q2hc4FPi7JDuOHX9WVe3fbOes9II2O5IkaZ4OA05ubp8MHL75CVX1+aq6qLn9VeAbwC5b+4I2O5Ik9dzSnLck65JsHNvWTVHurlV1eXP7a8CubScnOQjYFvjC2O7nN8NbL02y3Uov6GosSZI0lapaD6zf0vEkHwRuucyh52z2PJVki4vJkuwGvAE4uqo2XU7oWEZN0rZNDccAJ7bVa7MjSVLPrbWLClbVIVs6luTrSXarqsubZuYbWzjvpsB7gOdU1Vljz70pFbo6yT8Dz1ypHoexJEnSPJ0GHN3cPhp41+YnJNkWeAfw+qp622bHdmu+htF8n/NXekGbHUmSeq7mvK3SC4EHJbkIOKS5T5IDk7ymOecxwP2Axy2zxPxNSc4DzgNuATxvpRd0GEuSJM1NVX0LeOAy+zcCT2huvxF44xYef/C0r2mzI0lSz632Qn9D5zCWJEkaNJMdSZJ6bq2txlprTHYkSdKgmexIktRzM1ghNWgmO5IkadBMdiRJ6rkls51WEzU7SXZeZvf3quraGdcjSZI0U5MmO58C9gC+DQTYEfhakq8DT6yqT3ZTniRJWomrsdpNOmfndOChVXWLqro58BDg3cCTgFd2VZwkSdJqTdrs3Kuq3r/pTlV9ALh38ymk23VSmSRJ0gxMOox1eZJjgFOb+0cAX0+yDaZnkiQtlNOT202a7PwOsDvwzmbbs9m3DaNPJpUkSVqTJkp2quoK4ClbOHzx7MqRJEnTcoil3aRLz3cB/gzYF9h+0/6t+Zh1SZKkeZp0GOtNwIXAXsBfAl8CNnRUkyRJmsJS5rv1zaTNzs2r6rXAtVX10ar6fcBUR5IkrXmTrsbadKXky5M8DPgqsNxVlSVJ0pz5cRHtJm12npfkZsAzgJcDNwWe3llVkiRJMzLpaqx3NzevAh4wyWOSrAPWAbzkjnvz2FvttlUFSpKkduY67SZdjbUXo6Xntx1/TFU9YkuPqar1wHqArz/g1/17kCRJCzHpMNY7gdcC/4bL+SVJWlP8wdxu0mbnx1X1sk4rkSRJ6sCkzc7fJzke+ABw9aadVfWpTqqSJEkTczVWu0mbnf2AxzK6ts6mtKzwWjuSJGmNm7TZeTRwu6q6pstiJEnS9Mx12k16BeXzgR07rEOSJKkTkyY7OwIXJtnAT+bsVFUd1klVkiRJMzJps3P82O0AvwYcOftyJEnStFx63m6iYayq+ijwXeDhwOsYTUz+p+7KkiRJmo3WZCfJHYGjmu0K4M1Aqmqij4yQJEndc+l5u5WGsS4EPgY8vKouBkjiB4BKkqTeWGkY65HA5cCHk7w6yQMZzdmRJElrRM1565vWZqeq3llVRwL7AB8G/gT4pST/mOTBc6hPkiRpVSadoPyDqvqXqvpNYHfg08AxnVYmSZImsjTnrW8mvajg/6qqb1fV+qp6YBcFSZIkzdKk19mRJElrVPVyJs38TJ3sSJIk9YnJjiRJPdfHeTTzZLIjSZIGzWRHkqSe8wrK7Ux2JEnSoJnsSJLUc+Y67Ux2JEnSoJnsSJLUc87ZaWeyI0mSBs1mR5IkDZrDWJIk9ZwXFWxnsiNJkgbNZEeSpJ7zg0DbmexIkqRBM9mRJKnnnLPTzmRHkiQN2lySnTM/e+t5vMzC7PHCyxddQqe+cv2tFl1Cpx5z5UcXXUJnvrvnQxZdQqfO3PeYRZfQqft85kWLLqFT177uBYsuYTCcs9POZEeSJA2ac3YkSeo55+y0M9mRJEmDZrIjSVLPLZVzdtqY7EiSpEEz2ZEkqefMddqZ7EiSpEGz2ZEkqeeWqLluq5Fk5ySnJ7mo+brTFs67Psk5zXba2P69kvxXkouTvDnJtiu9ps2OJEmap2cDZ1TV3sAZzf3l/Kiq9m+2R4ztfxHw0qq6A/Bt4PErvaDNjiRJmqfDgJOb2ycDh0/6wCQBDgbeNs3jbXYkSeq5mvN/SdYl2Ti2rZui3F2ratPnLH0N2HUL523fPPdZSQ5v9t0c+E5VXdfcvxRY8TOpXI0lSZKmUlXrgfVbOp7kg8Atlzn0nM2ep5JsaRLQbarqsiS3Az6U5Dzgqq2p12ZHkqSeW2sfF1FVh2zpWJKvJ9mtqi5PshvwjS08x2XN10uSfAQ4AHg7sGOSGzbpzu7AZSvV4zCWJEmap9OAo5vbRwPv2vyEJDsl2a65fQvgPsAFVVXAh4FHtT1+czY7kiT1XJ+WngMvBB6U5CLgkOY+SQ5M8prmnDsDG5P8N6Pm5oVVdUFz7BjgT5NczGgOz2tXekGHsSRJ0txU1beABy6zfyPwhOb2x4H9tvD4S4CDpnlNmx1Jknqu/MCIVg5jSZKkQTPZkSSp59baaqy1xmRHkiQNmsmOJEk9N1qRrS0x2ZEkSYNmsiNJUs/N4No3gzZxs5PklozWtRewoaq+1llVkiRJMzLRMFaSJwBnA49kdInms5L8fpeFSZKkySzNeeubSZOdZwEHNFc9JMnNgY8DJ3VVmCRJ0ixMOkH5W8D3xu5/r9knSZK0pk2a7FwM/FeSdzGas3MYcG6SPwWoqv/XUX2SJGkFflxEu0mbnS802yabPk59h9mWI0mSNFsTNTtV9ZddFyJJkraOS8/bTdTsJDkQeA5wm/HHVNVdO6pLkiRpJiYdxnoToxVZ59HPVWeSJA2WHxfRbtJm55tVdVqnlUiSJHVg0mbn+CSvAc4Art60s6r+dUsPSLIOWAfwBzvckwff5A6rqVOSJG2BQy7tJm12/i+wD3AjfvJnWsAWm52qWg+sB/jXW/6O+ZokSVqISZude1bVnTqtRJIkbRWvs9Nu0isofzzJXTqtRJIkqQOTJjv3As5J8kVGc3YClEvPJUlaPK+z027SZufQTquQJEnqyETDWFX1ZWAP4ODm9g8nfawkSepWVc1165uJGpYkxwPHAMc2u24EvLGroiRJkmZl0mGs3wIOAD4FUFVfTeKHgEqStAY4Z6fdpENR19QotyqAJL/QXUmSJEmzM2mz85YkrwJ2TPJE4IPAq7srS5IkaTYmHcbaBXgb8F3gTsBxwCFdFSVJkibnRQXbTdrsPKiqjgFO37Qjyd8ymrQsSZK0ZrU2O0n+CHgScLsk544d2gE4s8vCJEnSZJZ6uBx8nlZKdv4F+Hfgr4Fnj+3/XlVd2VlVkiRJM9La7FTVVcBVwFHzKUeSJE3LXKedV0GWJEmDNukEZUmStEZ5UcF2JjuSJGnQTHYkSeo5k512JjuSJGnQTHYkSeq58jo7rUx2JEnSoJnsSJLUc87ZaWeyI0mSBs1kR5KknvNTz9uZ7EiSpEGz2ZEkSYPmMJYkST3n0vN2JjuSJGnQTHYkSeo5l563M9mRJEmDZrIjSVLPOWenncmOJEkatLkkO/v8wlXzeJmF2e3uP1h0CZ3absN1iy6hU/feZZ9Fl9CZGz3uzxddQqfu8T9PXXQJnbr2dS9YdAmdGvq/z3lyzk47kx1JkjRoztmRJKnn/LiIdiY7kiRp0Ex2JEnquSVXY7Uy2ZEkSYNmsiNJUs85Z6edyY4kSRo0kx1JknrOOTvtTHYkSdKg2exIkqS5SbJzktOTXNR83WmZcx6Q5Jyx7cdJDm+OvS7JF8eO7b/Sa9rsSJLUczXn/1bp2cAZVbU3cEZz/6ffT9WHq2r/qtofOBj4IfCBsVOetel4VZ2z0gva7EiSpHk6DDi5uX0ycPgK5z8K+Peq+uHWvqDNjiRJPbdUNdctybokG8e2dVOUu2tVXd7c/hqw6wrnHwmcstm+5yc5N8lLk2y30gu6GkuSJE2lqtYD67d0PMkHgVsuc+g5mz1PJdniuFiS3YD9gPeP7T6WUZO0bVPDMcCJbfXa7EiS1HNr7aKCVXXIlo4l+XqS3arq8qaZ+UbLUz0GeEdVXTv23JtSoauT/DPwzJXqcRhLkiTN02nA0c3to4F3tZx7FJsNYTUNEknCaL7P+Su9oMmOJEk917OLCr4QeEuSxwNfZpTekORA4A+r6gnN/dsCewAf3ezxb0qyCxDgHOAPV3pBmx1JkjQ3VfUt4IHL7N8IPGHs/peAWy9z3sHTvqbNjiRJPbfW5uysNc7ZkSRJg2ayI0lSz1UtLbqENW3iZCfJXpPskyRJWkumGcZ6+zL73jarQiRJ0tZZoua69c2Kw1hJ9gH2BW6W5JFjh24KbN9VYZIkSbMwyZydOwEPB3YEfnNs//eAJ3ZQkyRJmkL16zo7c7dis1NV7wLeleTeVfWJOdQkSZI0M5MMY70cRgN0SY7a/HhVPbWDuiRJkmZikmGsjZ1XIUmStlofJw3P0yTDWCfPoxBJkqQuTHxRwSQfhp9tHbfmMyokSdLsOEG53TRXUH7m2O3tgd8GrpttOZIkSbM1cbNTVZ/cbNeZSc6ecT2SJGlKSyY7raYZxtp57O4NgHsAN5t5RZIkSTM0zTDWJxnN2Qmj4asvAo/f0slJ1gHrAI6/xS/zmJvuuYoyJUnSlpSrsVpNM4w11Yd+VtV6YD3ABbd/mH8LkiRpIab51PNHJ9mhuf3cJP+a5O7dlSZJkiZRVXPd+maaTz3/i6r6XpL7AocArwX+sZuyJEmSZmOaZuf65uvDgPVV9R5g29mXJEmSprFEzXXrm2mancuSvAo4Anhvku2mfLwkSdLcTbMa6zHAocDfVNV3kuwGPKubsiRJ0qT6OI9mniZOZqrqh8A3gPs2u64DLuqiKEmSpFmZ5qKCxwMHAncC/hm4EfBG4D7dlCZJkibhFZTbTTPn5reARwA/AKiqrwI7dFGUJEnSrEzT7FxTo0HBAkjyC92UJEmSNDsTDWMlCfDuZjXWjkmeCPw+8Ooui5MkSStzgnK7iZqdqqokjwb+FPguo3k7x1XV6V0WJ0mStFrTLD3/FPCdqnK5uSRJa0gfL/Q3T9M0O78C/G6SL9NMUgaoqrvOvCpJkqQZmabZ+Y3OqpAkSVvNOTvtJm52qurLXRYiSZLUhWmSHUmStAZ5UcF2fpCnJEkaNJMdSZJ6rlyN1cpkR5IkDZrJjiRJPeecnXYmO5IkadBMdiRJ6jmvs9POZEeSJA2ayY4kST3naqx2JjuSJGnQbHYkSdKgOYwlSVLPOUG5ncmOJEkaNJMdSZJ6zmSnncmOJEkaNJMdSZJ6zlynncmOJEkatAxxnC/Juqpav+g6uuL7668hvzfw/fWd709DNdRkZ92iC+iY76+/hvzewPfXd74/DdJQmx1JkiTAZkeSJA3cUJudoY/J+v76a8jvDXx/fef70yANcoKyJEnSJkNNdiRJkgCbHUmSNHBrutlJ8uEkv7HZvj9J8o+Lqmleklyf5Jwk5yd5a5KbNPu/v+ja1G7s7+6/k3wqya8uc84lSe602b6/S3LM/Cr9WUmek+QzSc5t3sOvtJx3TrNdP3b7qfOueTWSHJ6kkuyz6FpmLcmOSZ606Dr6IsnjkvxDc/vwJHdZdE2anTXd7ACnAEdutu/IZv/Q/aiq9q+qXwauAf5w0QV1LcmXkpzX/KD9QJJbju2/xaLrm8Kmv7u7AccCf73MOacy9m87yQ2ARzX7FyLJvYGHA3evqrsChwBfWe7cqnp+8x735yfvd/+qetn8Kp6Jo4D/bL4OzY7A4JudjMz6Z9nhgM3OgKz1ZudtwMOSbAuQ5LbArYBtknw0ybua35BfmOR3k5zd/LC8fXP+byb5rySfTvLBJLs2+3dJcnrzG+xrknx5jf8w/Rhwh/EdSX4ryRnN/+i7Jfn8puag5x7Q/KDdCPz5oouZgZsC315m/ynAEWP37wd8uaq+PJeqlrcbcEVVXQ1QVVdU1VebZvPFzf9bZye5w3IPTnJikj8Zu//8JE9Lcv8k/5HkPUk+l+SfNv1wSvLgJJ9oErC3JvnFebzR5rV/Ebgv8HiaxrOpdSjfW14I3L5J3F6S5FlJNjS/TPxlU+9tk1yY5HXN95A3JTkkyZlJLkpyUHPeCUne0PxdXZTkiQt6T4zV/bkkrwfOB/5imff2C82/uf/OKCE/otn/v788JTkwyUc2e+5fBR4BvKT5s7v9XN+cOrGmm52quhI4G3hIs+tI4C2MPvPsbozSjjsDjwXuWFUHAa8BntKc/5/AvarqAEa/Mf9Zs/944ENVtS+jhmrP7t/N1klyQ0bv/7zx/VX1DuBy4I+BVwPHV9XX5l/hypL8n+aHxTlJXpVkmwke9h/8bIN3z+ab2fbNN7LPJPnlbqpelRs37/VCRv8e/2rzE6rqPGApyd2aXWshsfwAsEfzQ++VSX597NhVVbUf8A/A323h8ScBvwf/m1QdCbyxOXYQo/8v7wLcHnhk8wPnucAhVXV3Rg3un872LbU6DHhfVX0e+FaSezT7h/K95dnAF5r07XRgb0Z/D/sD90hyv+a8OwB/C+zTbL/DqAl8Jj/9C8ddgYOBewPHJblV92+h1d7AK4GnA7fmZ9/bocBXq+puTUL+vkmetKo+DpwGPKtJK7/QRfGarzXd7DTGh7LGfyBsqKrLm99Cv8DoGzWMmoLbNrd3B96f5DzgWcC+zf770gwXVNX7WP4370W7cZJzGP0A+B/gtcuc8xRGwyRXV9Wif1AuK8mdGSUY92m+6V4P/O4ED304P9vgbWD0Teh5wIuBN1bV+TMteDY2Devsw+gb7uuTZJnzTgGObBraw4G3zrHGn1FV3wfuweiS+t8E3pzkcc3hU8a+3nsLj/8So6bhAODBwKer6lvN4bOr6pKqur55jvsC92LU/JzZ/Fs/GrjNjN9Wm6P4ybDhqfxkKGuI31se3GyfBj7FqKnZuzn2xao6r6qWgM8AZ9TomiTj7xfgXVX1o6q6Avgwo+Zikb5cVWex5fd2HvCgJC9K8mtVddXiStWi3XDRBUzgXcBLk9wduElVfTLJ/YGrx85ZGru/xE/e18uB/1dVpzWPOWEO9c7Kj5rmoM3ujN7vrklu0HyzWmseyOgH6Ibm5/2NgW+0nP/hJNcD5zL6rX9zJwIbgB8Da34ybFV9okkwdknyNOBhzf79Gf1Q/ADwUeDcqvr6wgptNM3IR4CPND/Ij950aPy0lqd4DfA44JaMkp4tPaaAAKdX1dznyyTZmVFKsV+SArZpanoPw/zeEuCvq+pVP7VzNDVgkvcLy/8dLtIPmq/LvjeA5ufGQ4HnJTmjqk4EruMnv+hvP5dKtXBrPtlpftv8MKNvnNOmFzcDLmtuHz22/0zgMTCaMwDstMoy565JA05i9NvoZ5lv/D+NACePTWC9U1Wd0HL+A5rzfq+qvrPM8ZsDvwjsQA++UWW0ymcb4FtV9ZyxSb008fgVjOZWLDyZS3KnJHuP7dof2DSH6Iixr59oeZp3MEqz7gm8f2z/QUn2aoa3jmA0DHQWcJ80c4Caock7rvqNTOZRwBuq6jZVdduq2gP4IvBrEz6+D99bvsfo/xMY/V38/qY5UUluneSXpny+w5oh5JsD92f0S8dasOx7a4bZflhVbwReAty9Of9LjH4BA/jtLTzn+J+dBmDNNzuNUxiNo0/7A+EE4K1JPsnoh8omfwk8OMn5wKOBrzH6x90nfw58rKr+k1Gj84RmyGitOQN41KZvrEl2TrKaoYpXAX8BvAl40Qzq68KmOTvnAG8Gjm4Sk+Wcwih2/9d5FdfiF4GTk1yQ5FxGQ0wnNMd2avY9jdEciWVV1TWMfjl5y2bveQOj+T6fZdRUvKOqvskoBTqlee5PMPqzmIejGDVm497O5KuyTmCNf29phhDPbGp5EPAvwCeaxO5tTP/D/FxGf7dnAX9VVV+dZb1bq6o+wPLvbT/g7Ob/w+MZDX/D6O/o75NsZDSsvpxTgWdlNAHdCcoD8HP5cRFJtgOur6rrMlpu+48TDBlpKzWrII5l1FxfC/xxM9a++XlfAg5s5gT8zH5GcfRhVfXbzSTnjwPHVtWHun0HP9+29PeyhXNvwGjexKOr6qJm3/2BZ1bVwzssc00Y6veWJCcA36+qv1l0LdLW6MOcnS7sCbyl+cZ8DbDQZZRDV1VvZpRwrHTebVfY//pm2zS3ZNkL3mkxMroI27sZpTYXLbqeBfF7i7QG/VwmO5Ik6efHz2uyowVK8l/Adpvtfmxz7RlJkmbKZEeSJA1aX1ZjSZIkbRWbHUmSNGg2O5IkadBsdiRJ0qD9f5gSvnWPh60AAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = data['TargetClass']\n",
    "X = data.drop(columns=['TargetClass'])\n",
    "# X = data[[\"temp\", \"Amag\", \"SpType\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5, test_size=0.2, stratify=y)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "X_test2 = X_test.copy()\n",
    "X_test2[\"result\"] = y_test\n",
    "data_ploting = X_test2.corr(method='pearson')\n",
    "sns.heatmap(data_ploting, linecolor='black')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "       Vmag       Plx     e_Plx       B-V  SpType      Amag  TargetClass  \\\n1  0.423018  0.044991  0.042741  0.555190     0.0  0.350098          0.0   \n2  0.705768  0.153779  0.047013  0.354782     1.0  0.570943          1.0   \n3  0.724704  0.044363  0.089611  0.615200     0.0  0.470053          0.0   \n4  0.717927  0.067391  0.098939  0.551081     0.0  0.507096          0.0   \n5  0.308357  0.146486  0.062652  0.534635     0.0  0.412545          0.0   \n\n       temp  \n1  0.081891  \n2  0.164016  \n3  0.065528  \n4  0.083111  \n5  0.088135  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vmag</th>\n      <th>Plx</th>\n      <th>e_Plx</th>\n      <th>B-V</th>\n      <th>SpType</th>\n      <th>Amag</th>\n      <th>TargetClass</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.423018</td>\n      <td>0.044991</td>\n      <td>0.042741</td>\n      <td>0.555190</td>\n      <td>0.0</td>\n      <td>0.350098</td>\n      <td>0.0</td>\n      <td>0.081891</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.705768</td>\n      <td>0.153779</td>\n      <td>0.047013</td>\n      <td>0.354782</td>\n      <td>1.0</td>\n      <td>0.570943</td>\n      <td>1.0</td>\n      <td>0.164016</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.724704</td>\n      <td>0.044363</td>\n      <td>0.089611</td>\n      <td>0.615200</td>\n      <td>0.0</td>\n      <td>0.470053</td>\n      <td>0.0</td>\n      <td>0.065528</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.717927</td>\n      <td>0.067391</td>\n      <td>0.098939</td>\n      <td>0.551081</td>\n      <td>0.0</td>\n      <td>0.507096</td>\n      <td>0.0</td>\n      <td>0.083111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.308357</td>\n      <td>0.146486</td>\n      <td>0.062652</td>\n      <td>0.534635</td>\n      <td>0.0</td>\n      <td>0.412545</td>\n      <td>0.0</td>\n      <td>0.088135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression()\n",
    "model3.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 s, sys: 15.5 ms, total: 3.07 s\n",
      "Wall time: 3.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "GradientBoostingRegressor()"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# xgb = XGBClassifier(subsample=0.8,\n",
    "#                     min_child_weight=1,\n",
    "#                     max_depth=14,\n",
    "#                     gamma=1,\n",
    "#                     colsample_bytree=0.8)\n",
    "xgb = GradientBoostingRegressor()\n",
    "xgb.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "pred = xgb.predict(X_test)\n",
    "pred_ = pd.Series(model2.predict(X_test))\n",
    "pred__ = pd.Series(model3.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.0\n1    0.0\n2    1.0\n3    0.0\n4    0.0\ndtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred__.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9991661510113334, 0.999366087087813, 0.997639073573955)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred), roc_auc_score(y_test, pred_), roc_auc_score(y_test, pred__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "custom_model = D1ffic00ltLinearRegression()\n",
    "custom_model.set_x_test(X_test)\n",
    "custom_model.set_y_true(y_test)\n",
    "best_score = {}\n",
    "for i in range(-500, 500):\n",
    "    best_score[i] = custom_model.fit_with_l2(X_train, y_train, L=i, predict=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "{-500: 0.8216256462732335,\n -499: 0.8138121023863194,\n -498: 0.8056712375812036,\n -497: 0.7971302205025308,\n -496: 0.7880911490014683,\n -495: 0.7784844131095319,\n -494: 0.768181857653357,\n -493: 0.7568668062974472,\n -492: 0.7445347771122424,\n -491: 0.7310112549654877,\n -490: 0.7162920380482206,\n -489: 0.7002401473882535,\n -488: 0.6828177667049218,\n -487: 0.6642656596517933,\n -486: 0.6444766801003168,\n -485: 0.6238219878422058,\n -484: 0.6024001853277873,\n -483: 0.5803832666039384,\n -482: 0.5579407046321582,\n -481: 0.5351656395111224,\n -480: 0.5124618650821552,\n -479: 0.4900205636530639,\n -478: 0.46783809365608087,\n -477: 0.5538950629024808,\n -476: 0.5750850656224518,\n -475: 0.5955236448395763,\n -474: 0.6153727102592208,\n -473: 0.6343892572630369,\n -472: 0.6526893958386965,\n -471: 0.6702844708703992,\n -470: 0.6870082307835169,\n -469: 0.703179592878326,\n -468: 0.7188129833655986,\n -467: 0.7340327757906334,\n -466: 0.748853816545099,\n -465: 0.7632590182725467,\n -464: 0.7777168826723282,\n -463: 0.792005414170909,\n -462: 0.8061183100548448,\n -461: 0.8201961908640908,\n -460: 0.834208103272621,\n -459: 0.8480862580958354,\n -458: 0.8616317697094953,\n -457: 0.8747760085672084,\n -456: 0.8875154731615056,\n -455: 0.8996298486424374,\n -454: 0.9111874844357993,\n -453: 0.9220086831782819,\n -452: 0.931907024612236,\n -451: 0.9410776127338341,\n -450: 0.9493632998878676,\n -449: 0.9568142276612925,\n -448: 0.9634250737627563,\n -447: 0.9691381333491694,\n -446: 0.9740903853927194,\n -445: 0.978249616024691,\n -444: 0.981744540659645,\n -443: 0.984581462011025,\n -442: 0.9868991798349024,\n -441: 0.9887972770036957,\n -440: 0.9902999839490898,\n -439: 0.9914874151619756,\n -438: 0.9924350631433845,\n -437: 0.9931778029077077,\n -436: 0.9937554115797933,\n -435: 0.99422559400273,\n -434: 0.9945884902368168,\n -433: 0.9948859783113827,\n -432: 0.9951441094419969,\n -431: 0.9953484574178876,\n -430: 0.9955284349017939,\n -429: 0.9956794199038569,\n -428: 0.9957941292885413,\n -427: 0.9958806865531747,\n -426: 0.9959626218279494,\n -425: 0.9960389546907734,\n -424: 0.9960874155541444,\n -423: 0.9961290134628761,\n -422: 0.9961557649799391,\n -421: 0.9961713116731016,\n -420: 0.9961825164970023,\n -419: 0.996188539089849,\n -418: 0.9961928809591105,\n -417: 0.9961962424062809,\n -416: 0.996200164094646,\n -415: 0.9962024050594261,\n -414: 0.9962049261448038,\n -413: 0.9962068869889865,\n -412: 0.9962082875919741,\n -411: 0.9962092680140654,\n -410: 0.9962103884964554,\n -409: 0.9962117890994431,\n -408: 0.9962131897024308,\n -407: 0.9962144502451196,\n -406: 0.9962148704260156,\n -405: 0.9962154306672109,\n -404: 0.996216411089302,\n -403: 0.9962182318731861,\n -402: 0.996219352355576,\n -401: 0.9962207529585636,\n -400: 0.9962231339836426,\n -399: 0.9962253749484228,\n -398: 0.9962259351896179,\n -397: 0.9962290165161907,\n -396: 0.9962302770588793,\n -395: 0.9962318177221656,\n -394: 0.9962337785663484,\n -393: 0.9962357394105309,\n -392: 0.9962375601944148,\n -391: 0.9962392409179999,\n -390: 0.9962416219430787,\n -389: 0.9962441430284567,\n -388: 0.9962472243550293,\n -387: 0.9962493252595107,\n -386: 0.9962522665257847,\n -385: 0.9962545074905648,\n -384: 0.99625730869654,\n -383: 0.9962598297819177,\n -382: 0.9962610903246065,\n -381: 0.9962644517717767,\n -380: 0.9962668327968557,\n -379: 0.9962678132189469,\n -378: 0.9962703343043245,\n -377: 0.9962729954500011,\n -376: 0.9962755165353786,\n -375: 0.9962771972589639,\n -374: 0.9962780376207564,\n -373: 0.9962791581031465,\n -372: 0.9962806987664328,\n -371: 0.9962827996709144,\n -370: 0.9962846204547982,\n -369: 0.9962849005753956,\n -368: 0.9962874216607733,\n -367: 0.9962882620225659,\n -366: 0.9962889623240596,\n -365: 0.9962921837109311,\n -364: 0.9962944246757114,\n -363: 0.9962947047963089,\n -362: 0.9962962454595953,\n -361: 0.9962977861228814,\n -360: 0.9962970858213879,\n -359: 0.9962976460625828,\n -358: 0.9962982063037779,\n -357: 0.9962955451581015,\n -356: 0.9962903629270474,\n -355: 0.9962895225652547,\n -354: 0.9962871415401758,\n -353: 0.9962847605150968,\n -352: 0.9962837800930054,\n -351: 0.9962755165353786,\n -350: 0.9962587092995274,\n -349: 0.9962536671287722,\n -348: 0.9963031084142344,\n -347: 0.996434064793575,\n -346: 0.9961468011208185,\n -345: 0.9491908856600944,\n -344: 0.813790112919414,\n -343: 0.9954354348634175,\n -342: 0.9978948937096398,\n -341: 0.9976838228394088,\n -340: 0.9975056661393863,\n -339: 0.9973839537397639,\n -338: 0.9972999175605083,\n -337: 0.9972356298833773,\n -336: 0.9971930515525543,\n -335: 0.9971576162969681,\n -334: 0.9971300244181124,\n -333: 0.997109855735091,\n -332: 0.9970940289213311,\n -331: 0.9970845048210155,\n -330: 0.9970769415648825,\n -329: 0.9970721795147246,\n -328: 0.9970697984896458,\n -327: 0.9970696584293469,\n -326: 0.9970700786102432,\n -325: 0.9970721795147246,\n -324: 0.9970751207809986,\n -323: 0.9970817036150402,\n -322: 0.9970885665696796,\n -321: 0.9970959897655136,\n -320: 0.9971055138658294,\n -319: 0.9971155982073402,\n -318: 0.9971270831518385,\n -317: 0.9971370274330504,\n -316: 0.997146691593665,\n -315: 0.9971598572617482,\n -314: 0.9971706419047529,\n -313: 0.9971838075728363,\n -312: 0.9971944521555419,\n -311: 0.9972080380045217,\n -310: 0.997221343732904,\n -309: 0.9972346494612859,\n -308: 0.997246834707278,\n -307: 0.997260280495959,\n -306: 0.9972730259831463,\n -305: 0.9972875922542173,\n -304: 0.9973018784046908,\n -303: 0.9973165847360606,\n -302: 0.9973303106453391,\n -301: 0.9973468377605926,\n -300: 0.9973614040316636,\n -299: 0.9973747097600458,\n -298: 0.9973929175988846,\n -297: 0.9974100049553333,\n -296: 0.9974262519499894,\n -295: 0.9974427790652433,\n -294: 0.9974577655172102,\n -293: 0.9974720516676839,\n -292: 0.9974874583005474,\n -291: 0.997502864933411,\n -290: 0.997516870963287,\n -289: 0.9975357791036196,\n -288: 0.9975499251937944,\n -287: 0.9975679929723343,\n -286: 0.997583959846393,\n -285: 0.9976007670822442,\n -284: 0.9976189749210829,\n -283: 0.9976350818554405,\n -282: 0.9976524493324866,\n -281: 0.997673178256703,\n -280: 0.9976953077839071,\n -279: 0.9977178574920074,\n -278: 0.9977373258735351,\n -277: 0.9977531526872949,\n -276: 0.9977696798025485,\n -275: 0.9977869072192961,\n -274: 0.9978034343345497,\n -273: 0.9978244433793637,\n -272: 0.9978475533286592,\n -271: 0.9978680021322779,\n -270: 0.9978895714182869,\n -269: 0.9979084795586195,\n -268: 0.9979308892064213,\n -267: 0.9979535789748202,\n -266: 0.9979694057885801,\n -265: 0.9979883139289126,\n -264: 0.9980104434561167,\n -263: 0.9980317326215281,\n -262: 0.9980502205809646,\n -261: 0.9980664675756206,\n -260: 0.9980862160777458,\n -259: 0.9981094660873399,\n -258: 0.9981308953130501,\n -257: 0.9981488230312914,\n -256: 0.9981667507495328,\n -255: 0.998186359191359,\n -254: 0.9982065278743805,\n -253: 0.9982203938439577,\n -252: 0.9982405625269791,\n -251: 0.9982561092201413,\n -250: 0.9982747372398765,\n -249: 0.9982943456817029,\n -248: 0.9983110128572553,\n -247: 0.9983271197916125,\n -246: 0.9983422463038786,\n -245: 0.9983589134794311,\n -244: 0.9983754405946847,\n -243: 0.9983902869863533,\n -242: 0.998403872835333,\n -241: 0.9984229210359644,\n -240: 0.9984351062819565,\n -239: 0.9984519135178076,\n -238: 0.9984698412360489,\n -237: 0.9984828668438336,\n -236: 0.9984961725722158,\n -235: 0.9985111590241831,\n -234: 0.9985254451746565,\n -233: 0.9985365099382585,\n -232: 0.9985521966917198,\n -231: 0.9985659226009981,\n -230: 0.9985803488117704,\n -229: 0.9985971560476216,\n -228: 0.9986097614745099,\n -227: 0.9986220867808009,\n -226: 0.9986316108811164,\n -225: 0.9986433759462122,\n -224: 0.998654020528918,\n -223: 0.9986659256543127,\n -222: 0.998677970840006,\n -221: 0.9986908563874918,\n -220: 0.9987008006687039,\n -219: 0.9987132660352936,\n -218: 0.998723350376804,\n -217: 0.9987338548992111,\n -216: 0.9987466003863984,\n -215: 0.9987576651500004,\n -214: 0.9987676094312123,\n -213: 0.9987778338330219,\n -212: 0.9987877781142338,\n -211: 0.9987964618527568,\n -210: 0.9988064061339688,\n -209: 0.9988157901739858,\n -208: 0.9988243338522101,\n -207: 0.9988335778319282,\n -206: 0.9988407209071649,\n -205: 0.9988435221131401,\n -204: 0.9988407209071649,\n -203: 0.9988265748169902,\n -202: 0.9987814754007894,\n -201: 0.9986695672220804,\n -200: 0.9984206800711843,\n -199: 0.9978817280415564,\n -198: 0.9967738510783662,\n -197: 0.9946139812111912,\n -196: 0.9905439689895295,\n -195: 0.983083937296685,\n -194: 0.9696335266258832,\n -193: 0.9460433105660649,\n -192: 0.9060105756730387,\n -191: 0.842240421346198,\n -190: 0.7486752396641803,\n -189: 0.6260542688838399,\n -188: 0.5145190707503394,\n -187: 0.6520956802322535,\n -186: 0.7684056740107751,\n -185: 0.855122887505529,\n -184: 0.9135847565093724,\n -183: 0.9503183710651111,\n -182: 0.9720826210099973,\n -181: 0.9841897133553938,\n -180: 0.9905985925060456,\n -179: 0.9938369266736715,\n -178: 0.9953425748853396,\n -177: 0.9959340495270024,\n -176: 0.9961606670903957,\n -175: 0.9962407815812865,\n -174: 0.9962693538822335,\n -173: 0.9962769171383665,\n -172: 0.9962794382237441,\n -171: 0.9962797183443416,\n -170: 0.9962784578016527,\n -169: 0.9962762168368726,\n -168: 0.9962759367162751,\n -167: 0.9962732755705985,\n -166: 0.9962720150279099,\n -165: 0.996272435208806,\n -164: 0.9962706144249222,\n -163: 0.9962692138219346,\n -162: 0.9962668327968557,\n -161: 0.996265432193868,\n -160: 0.996264311711478,\n -159: 0.9962630511687892,\n -158: 0.9962609502643077,\n -157: 0.9962620707466979,\n -156: 0.9962623508672954,\n -155: 0.9962619306863991,\n -154: 0.9962610903246065,\n -153: 0.9962605300834115,\n -152: 0.9962592695407226,\n -151: 0.9962612303849054,\n -150: 0.9962613704452041,\n -149: 0.9962627710481916,\n -148: 0.9962627710481917,\n -147: 0.9962601099025153,\n -146: 0.9962587092995276,\n -145: 0.9962580089980339,\n -144: 0.9962585692392288,\n -143: 0.9962578689377352,\n -142: 0.9962573086965401,\n -141: 0.9962574487568389,\n -140: 0.9962567484553451,\n -139: 0.9962571686362414,\n -138: 0.9962556279729549,\n -137: 0.9962557680332537,\n -136: 0.9962564683347475,\n -135: 0.9962564683347475,\n -134: 0.9962574487568387,\n -133: 0.9962582891186313,\n -132: 0.9962585692392288,\n -131: 0.9962601099025152,\n -130: 0.9962617906261003,\n -129: 0.9962610903246065,\n -128: 0.9962592695407226,\n -127: 0.9962610903246065,\n -126: 0.9962615105055028,\n -125: 0.9962626309878929,\n -124: 0.9962622108069967,\n -123: 0.9962633312893868,\n -122: 0.996263191229088,\n -121: 0.9962644517717768,\n -120: 0.9962641716511793,\n -119: 0.9962640315908805,\n -118: 0.9962641716511794,\n -117: 0.9962652921335694,\n -116: 0.996266692736557,\n -115: 0.9962664126159594,\n -114: 0.9962661324953619,\n -113: 0.9962654321938681,\n -112: 0.9962673930380507,\n -111: 0.996267813218947,\n -110: 0.9962696340028309,\n -109: 0.9962708945455198,\n -108: 0.9962708945455198,\n -107: 0.9962732755705986,\n -106: 0.996273695751495,\n -105: 0.9962753764750801,\n -104: 0.9962771972589639,\n -103: 0.9962788779825491,\n -102: 0.9962798584046404,\n -101: 0.9962811189473293,\n -100: 0.9962815391282254,\n -99: 0.9962820993694206,\n -98: 0.9962837800930057,\n -97: 0.9962851806959933,\n -96: 0.9962865812989808,\n -95: 0.9962884020828646,\n -94: 0.9962900828064498,\n -93: 0.9962910632285412,\n -92: 0.9962930240727238,\n -91: 0.9962945647360102,\n -90: 0.9962965255801929,\n -89: 0.9962970858213878,\n -88: 0.9962986264846743,\n -87: 0.9963003072082594,\n -86: 0.9963022680524419,\n -85: 0.9963038087157282,\n -84: 0.9963059096202097,\n -83: 0.9963078704643923,\n -82: 0.9963082906452887,\n -81: 0.9963095511879775,\n -80: 0.996312212333654,\n -79: 0.9963140331175377,\n -78: 0.996315013539629,\n -77: 0.9963166942632142,\n -76: 0.9963185150470981,\n -75: 0.9963210361324757,\n -74: 0.9963222966751646,\n -73: 0.9963245376399449,\n -72: 0.9963246777002435,\n -71: 0.9963276189665174,\n -70: 0.99632845932831,\n -69: 0.9963311204739863,\n -68: 0.9963309804136877,\n -67: 0.9963323810166754,\n -66: 0.9963353222829493,\n -65: 0.9963363027050405,\n -64: 0.9963382635492232,\n -63: 0.996337843368327,\n -62: 0.9963392439713146,\n -61: 0.9963410647551983,\n -60: 0.9963426054184847,\n -59: 0.9963448463832648,\n -58: 0.9963442861420698,\n -57: 0.9963412048154973,\n -56: 0.9963475075289412,\n -55: 0.9963879849552829,\n -54: 0.9965283253746404,\n -53: 0.9968992050457562,\n -52: 0.997749651179826,\n -51: 0.9971219009207845,\n -50: 0.9966888344770192,\n -49: 0.9964857470438174,\n -48: 0.9963787409755648,\n -47: 0.9963318207754802,\n -46: 0.9963136129366414,\n -45: 0.9963109517909651,\n -44: 0.9963129126351477,\n -43: 0.9963206159515795,\n -42: 0.9963295798107001,\n -41: 0.9963426054184847,\n -40: 0.9963563313277632,\n -39: 0.9963700572370418,\n -38: 0.9963912063421545,\n -37: 0.9964255211153507,\n -36: 0.9964832259584396,\n -35: 0.9965825287102603,\n -34: 0.9967973812085579,\n -33: 0.9973487986047753,\n -32: 0.9979982582101247,\n -31: 0.9961827966175997,\n -30: 0.9961466610605199,\n -29: 0.996190359873733,\n -28: 0.9962238342851366,\n -27: 0.9962501656213034,\n -26: 0.9962750963544826,\n -25: 0.9962984864243754,\n -24: 0.9963217364339696,\n -23: 0.9963500286143191,\n -22: 0.9963944277290259,\n -21: 0.9964598358885467,\n -20: 0.9965640407508242,\n -19: 0.9967186673206548,\n -18: 0.9969457050649445,\n -17: 0.9972395515717427,\n -16: 0.9975730351430898,\n -15: 0.9979691256679826,\n -14: 0.9983429466053726,\n -13: 0.9973042594297696,\n -12: 0.9978625397806262,\n -11: 0.9982908441742337,\n -10: 0.9985811891735629,\n -9: 0.9987750326270466,\n -8: 0.9989173338905867,\n -7: 0.9990292420692958,\n -6: 0.9991127180073566,\n -5: 0.9991749047800058,\n -4: 0.9992246261860657,\n -3: 0.9992531984870127,\n -2: 0.9992737873509303,\n -1: 0.9992876533205076,\n 0: 0.999293255732458,\n 1: 0.9992975976017194,\n 2: 0.9992980177826158,\n 3: 0.9992956367575369,\n 4: 0.999293255732458,\n 5: 0.9992911548279766,\n 6: 0.9992845719939348,\n 7: 0.999280370184972,\n 8: 0.9992739274112291,\n 9: 0.9992632828285234,\n 10: 0.9992583807180667,\n 11: 0.9992495569192449,\n 12: 0.9992387722762404,\n 13: 0.9992295282965223,\n 14: 0.9992198641359077,\n 15: 0.9992107602164884,\n 16: 0.9992024966588615,\n 17: 0.9991918520761558,\n 18: 0.9991861096039066,\n 19: 0.9991779861065786,\n 20: 0.9991686020665618,\n 21: 0.9991606186295324,\n 22: 0.9991537556748932,\n 23: 0.9991466125996564,\n 24: 0.9991405900068098,\n 25: 0.9991335869918717,\n 26: 0.9991268640975312,\n 27: 0.9991205613840871,\n 28: 0.9991149589721366,\n 29: 0.9991085161983938,\n 30: 0.9991050146909247,\n 31: 0.999100252640767,\n 32: 0.9990967511332979,\n 33: 0.9990931095655301,\n 34: 0.9990870869726834,\n 35: 0.999083305344617,\n 36: 0.9990791035356541,\n 37: 0.9990740613648988,\n 38: 0.9990709800383261,\n 39: 0.9990680387720522,\n 40: 0.9990648173851806,\n 41: 0.9990624363601017,\n 42: 0.9990594950938277,\n 43: 0.9990565538275538,\n 44: 0.9990530523200848,\n 45: 0.9990510914759022,\n 46: 0.9990484303302256,\n 47: 0.9990461893654456,\n 48: 0.9990446487021593,\n 49: 0.9990421276167816,\n 50: 0.9990401667725989,\n 51: 0.9990383459887151,\n 52: 0.9990377857475199,\n 53: 0.9990370854460262,\n 54: 0.9990352646621423,\n 55: 0.9990335839385571,\n 56: 0.999031903214972,\n 57: 0.9990299423707893,\n 58: 0.9990289619486981,\n 59: 0.9990264408633204,\n 60: 0.9990251803206316,\n 61: 0.9990246200794366,\n 62: 0.9990229393558514,\n 63: 0.9990219589337601,\n 64: 0.9990201381498763,\n 65: 0.9990194378483825,\n 66: 0.9990177571247973,\n 67: 0.9990171968836024,\n 68: 0.9990152360394198,\n 69: 0.9990139754967309,\n 70: 0.9990136953761333,\n 71: 0.9990129950746395,\n 72: 0.9990125748937433,\n 73: 0.999011594471652,\n 74: 0.9990114544113532,\n 75: 0.9990113143510545,\n 76: 0.9990111742907557,\n 77: 0.9990107541098594,\n 78: 0.9990103339289631,\n 79: 0.9990100538083655,\n 80: 0.999009213446573,\n 81: 0.9990085131450792,\n 82: 0.9990078128435853,\n 83: 0.9990075327229879,\n 84: 0.9990072526023903,\n 85: 0.9990064122405977,\n 86: 0.9990054318185064,\n 87: 0.9990044513964152,\n 88: 0.9990048715773114,\n 89: 0.9990034709743238,\n 90: 0.9990029107331289,\n 91: 0.9990020703713364,\n 92: 0.9990020703713363,\n 93: 0.9990020703713363,\n 94: 0.9990015101301413,\n 95: 0.9990012300095438,\n 96: 0.9990009498889463,\n 97: 0.9990003896477512,\n 98: 0.99900052970805,\n 99: 0.9990005297080499,\n 100: 0.9990002495874524,\n 101: 0.9989996893462574,\n 102: 0.9990002495874524,\n 103: 0.9989988489844648,\n 104: 0.9989988489844647,\n 105: 0.9989984288035685,\n 106: 0.9989984288035685,\n 107: 0.9989982887432697,\n 108: 0.9989977285020747,\n 109: 0.9989971682608796,\n 110: 0.9989971682608797,\n 111: 0.9989968881402821,\n 112: 0.9989964679593858,\n 113: 0.9989964679593858,\n 114: 0.9989963278990871,\n 115: 0.9989961878387884,\n 116: 0.9989959077181908,\n 117: 0.9989961878387883,\n 118: 0.9989960477784896,\n 119: 0.9989959077181908,\n 120: 0.9989957676578921,\n 121: 0.9989956275975933,\n 122: 0.9989950673563983,\n 123: 0.9989950673563983,\n 124: 0.9989947872358008,\n 125: 0.998995207416697,\n 126: 0.9989950673563982,\n 127: 0.9989946471755019,\n 128: 0.998994647175502,\n 129: 0.9989950673563983,\n 130: 0.9989953474769958,\n 131: 0.9989950673563983,\n 132: 0.9989949272960995,\n 133: 0.998994647175502,\n 134: 0.9989945071152032,\n 135: 0.9989947872358008,\n 136: 0.9989949272960995,\n 137: 0.9989945071152032,\n 138: 0.9989940869343069,\n 139: 0.9989943670549044,\n 140: 0.9989939468740082,\n 141: 0.9989935266931119,\n 142: 0.998993526693112,\n 143: 0.998993526693112,\n 144: 0.9989932465725144,\n 145: 0.9989935266931119,\n 146: 0.9989936667534107,\n 147: 0.9989936667534107,\n 148: 0.998993526693112,\n 149: 0.9989938068137094,\n 150: 0.9989939468740081,\n 151: 0.9989936667534106,\n 152: 0.9989933866328131,\n 153: 0.9989931065122156,\n 154: 0.9989929664519168,\n 155: 0.9989925462710206,\n 156: 0.9989921260901243,\n 157: 0.9989921260901243,\n 158: 0.9989922661504231,\n 159: 0.9989922661504231,\n 160: 0.9989921260901242,\n 161: 0.9989921260901242,\n 162: 0.9989918459695267,\n 163: 0.9989918459695267,\n 164: 0.9989912857283317,\n 165: 0.9989911456680329,\n 166: 0.9989910056077342,\n 167: 0.9989911456680329,\n 168: 0.9989908655474355,\n 169: 0.9989905854268379,\n 170: 0.9989907254871366,\n 171: 0.9989907254871366,\n 172: 0.9989911456680329,\n 173: 0.9989910056077342,\n 174: 0.9989910056077341,\n 175: 0.9989911456680329,\n 176: 0.9989910056077342,\n 177: 0.9989911456680329,\n 178: 0.9989908655474354,\n 179: 0.9989912857283317,\n 180: 0.9989912857283317,\n 181: 0.9989914257886304,\n 182: 0.9989919860298254,\n 183: 0.9989918459695267,\n 184: 0.9989919860298255,\n 185: 0.9989919860298256,\n 186: 0.9989917059092279,\n 187: 0.9989918459695267,\n 188: 0.9989918459695267,\n 189: 0.9989919860298256,\n 190: 0.9989919860298255,\n 191: 0.9989919860298255,\n 192: 0.9989915658489292,\n 193: 0.998991705909228,\n 194: 0.998991705909228,\n 195: 0.998991705909228,\n 196: 0.9989918459695268,\n 197: 0.998991705909228,\n 198: 0.9989917059092281,\n 199: 0.9989918459695268,\n 200: 0.9989915658489293,\n 201: 0.998991145668033,\n 202: 0.9989910056077344,\n 203: 0.9989908655474355,\n 204: 0.9989908655474354,\n 205: 0.9989910056077342,\n 206: 0.9989914257886306,\n 207: 0.9989914257886305,\n 208: 0.9989914257886305,\n 209: 0.9989914257886305,\n 210: 0.9989914257886305,\n 211: 0.9989914257886305,\n 212: 0.9989915658489293,\n 213: 0.998991705909228,\n 214: 0.9989921260901243,\n 215: 0.9989919860298256,\n 216: 0.9989918459695267,\n 217: 0.9989919860298256,\n 218: 0.998991705909228,\n 219: 0.9989919860298256,\n 220: 0.9989918459695268,\n 221: 0.9989919860298255,\n 222: 0.9989919860298255,\n 223: 0.9989921260901242,\n 224: 0.9989921260901242,\n 225: 0.9989919860298255,\n 226: 0.9989921260901242,\n 227: 0.9989921260901242,\n 228: 0.9989919860298255,\n 229: 0.9989919860298255,\n 230: 0.9989918459695268,\n 231: 0.998991705909228,\n 232: 0.9989919860298255,\n 233: 0.9989921260901242,\n 234: 0.9989921260901242,\n 235: 0.998992266150423,\n 236: 0.998992266150423,\n 237: 0.9989921260901242,\n 238: 0.9989921260901242,\n 239: 0.9989921260901243,\n 240: 0.9989921260901243,\n 241: 0.9989921260901242,\n 242: 0.9989919860298255,\n 243: 0.9989921260901242,\n 244: 0.9989921260901242,\n 245: 0.9989922661504231,\n 246: 0.9989922661504231,\n 247: 0.9989924062107218,\n 248: 0.9989925462710205,\n 249: 0.9989926863313193,\n 250: 0.9989925462710206,\n 251: 0.9989924062107218,\n 252: 0.9989925462710205,\n 253: 0.9989925462710205,\n 254: 0.9989924062107218,\n 255: 0.998992266150423,\n 256: 0.9989921260901242,\n 257: 0.9989924062107218,\n 258: 0.9989919860298255,\n 259: 0.9989921260901242,\n 260: 0.9989921260901242,\n 261: 0.9989921260901242,\n 262: 0.998992266150423,\n 263: 0.9989924062107218,\n 264: 0.9989924062107218,\n 265: 0.9989924062107218,\n 266: 0.9989924062107218,\n 267: 0.9989924062107217,\n 268: 0.9989924062107217,\n 269: 0.9989925462710205,\n 270: 0.9989925462710205,\n 271: 0.9989924062107218,\n 272: 0.9989926863313193,\n 273: 0.9989928263916181,\n 274: 0.9989929664519168,\n 275: 0.998992826391618,\n 276: 0.998992826391618,\n 277: 0.9989929664519168,\n 278: 0.9989929664519168,\n 279: 0.9989931065122156,\n 280: 0.9989931065122156,\n 281: 0.9989932465725144,\n 282: 0.9989933866328132,\n 283: 0.9989933866328132,\n 284: 0.998993526693112,\n 285: 0.998993526693112,\n 286: 0.9989933866328131,\n 287: 0.9989933866328132,\n 288: 0.9989933866328132,\n 289: 0.9989932465725144,\n 290: 0.9989931065122157,\n 291: 0.9989932465725144,\n 292: 0.9989932465725144,\n 293: 0.9989932465725144,\n 294: 0.9989932465725144,\n 295: 0.998993526693112,\n 296: 0.998993526693112,\n 297: 0.9989936667534107,\n 298: 0.9989936667534107,\n 299: 0.9989936667534107,\n 300: 0.9989938068137095,\n 301: 0.9989938068137095,\n 302: 0.9989938068137095,\n 303: 0.9989938068137095,\n 304: 0.9989938068137095,\n 305: 0.9989938068137095,\n 306: 0.9989938068137095,\n 307: 0.9989938068137095,\n 308: 0.9989938068137095,\n 309: 0.998994086934307,\n 310: 0.998994086934307,\n 311: 0.998994086934307,\n 312: 0.998994086934307,\n 313: 0.9989940869343069,\n 314: 0.9989940869343069,\n 315: 0.9989939468740082,\n 316: 0.9989938068137094,\n 317: 0.9989938068137094,\n 318: 0.9989938068137094,\n 319: 0.9989939468740082,\n 320: 0.9989939468740082,\n 321: 0.9989939468740082,\n 322: 0.9989942269946057,\n 323: 0.9989942269946057,\n 324: 0.9989942269946057,\n 325: 0.9989943670549045,\n 326: 0.9989943670549045,\n 327: 0.9989943670549045,\n 328: 0.9989942269946057,\n 329: 0.9989942269946057,\n 330: 0.9989940869343069,\n 331: 0.9989942269946058,\n 332: 0.9989942269946058,\n 333: 0.9989942269946058,\n 334: 0.998994086934307,\n 335: 0.998994086934307,\n 336: 0.9989939468740082,\n 337: 0.9989939468740082,\n 338: 0.9989939468740082,\n 339: 0.9989938068137094,\n 340: 0.9989938068137094,\n 341: 0.9989938068137094,\n 342: 0.9989938068137094,\n 343: 0.9989938068137094,\n 344: 0.9989936667534106,\n 345: 0.9989936667534106,\n 346: 0.9989936667534106,\n 347: 0.9989939468740082,\n 348: 0.9989940869343069,\n 349: 0.9989940869343069,\n 350: 0.9989940869343069,\n 351: 0.9989939468740082,\n 352: 0.998994086934307,\n 353: 0.998994086934307,\n 354: 0.998994086934307,\n 355: 0.998994086934307,\n 356: 0.998994086934307,\n 357: 0.998994086934307,\n 358: 0.9989939468740082,\n 359: 0.9989939468740082,\n 360: 0.9989939468740082,\n 361: 0.9989938068137095,\n 362: 0.9989936667534106,\n 363: 0.9989938068137094,\n 364: 0.9989939468740082,\n 365: 0.998994086934307,\n 366: 0.998994086934307,\n 367: 0.9989943670549045,\n 368: 0.9989945071152032,\n 369: 0.9989945071152032,\n 370: 0.9989945071152032,\n 371: 0.9989946471755019,\n 372: 0.9989946471755019,\n 373: 0.9989949272960995,\n 374: 0.9989947872358008,\n 375: 0.9989947872358008,\n 376: 0.998994647175502,\n 377: 0.9989949272960995,\n 378: 0.9989949272960995,\n 379: 0.9989949272960995,\n 380: 0.9989952074166971,\n 381: 0.9989952074166971,\n 382: 0.9989952074166971,\n 383: 0.9989952074166971,\n 384: 0.9989952074166971,\n 385: 0.9989952074166971,\n 386: 0.9989950673563983,\n 387: 0.9989949272960995,\n 388: 0.9989947872358007,\n 389: 0.9989947872358007,\n 390: 0.9989947872358007,\n 391: 0.9989949272960995,\n 392: 0.9989949272960995,\n 393: 0.9989950673563982,\n 394: 0.9989950673563982,\n 395: 0.9989950673563982,\n 396: 0.9989952074166971,\n 397: 0.9989950673563983,\n 398: 0.9989950673563983,\n 399: 0.9989950673563983,\n 400: 0.9989950673563982,\n 401: 0.998995207416697,\n 402: 0.998995207416697,\n 403: 0.9989953474769958,\n 404: 0.9989953474769958,\n 405: 0.998995207416697,\n 406: 0.9989954875372945,\n 407: 0.9989956275975932,\n 408: 0.998995767657892,\n 409: 0.9989954875372945,\n 410: 0.9989954875372945,\n 411: 0.9989954875372945,\n 412: 0.9989954875372945,\n 413: 0.9989956275975932,\n 414: 0.9989956275975932,\n 415: 0.9989957676578921,\n 416: 0.9989957676578921,\n 417: 0.998995767657892,\n 418: 0.998995767657892,\n 419: 0.998995767657892,\n 420: 0.9989956275975932,\n 421: 0.9989956275975932,\n 422: 0.9989957676578921,\n 423: 0.9989957676578921,\n 424: 0.9989956275975932,\n 425: 0.9989956275975932,\n 426: 0.9989954875372945,\n 427: 0.9989956275975933,\n 428: 0.9989957676578921,\n 429: 0.9989957676578921,\n 430: 0.9989957676578921,\n 431: 0.9989957676578921,\n 432: 0.9989957676578921,\n 433: 0.9989957676578921,\n 434: 0.9989956275975933,\n 435: 0.9989956275975933,\n 436: 0.9989957676578921,\n 437: 0.9989957676578921,\n 438: 0.9989957676578921,\n 439: 0.9989960477784896,\n 440: 0.9989961878387884,\n 441: 0.9989960477784896,\n 442: 0.9989961878387884,\n 443: 0.9989961878387884,\n 444: 0.9989961878387884,\n 445: 0.9989961878387884,\n 446: 0.9989961878387884,\n 447: 0.9989963278990871,\n 448: 0.9989963278990871,\n 449: 0.9989961878387883,\n 450: 0.9989960477784895,\n 451: 0.9989960477784895,\n 452: 0.9989959077181908,\n 453: 0.9989959077181908,\n 454: 0.9989960477784895,\n 455: 0.9989960477784895,\n 456: 0.9989963278990872,\n 457: 0.9989963278990872,\n 458: 0.9989963278990872,\n 459: 0.9989963278990872,\n 460: 0.9989963278990872,\n 461: 0.9989964679593859,\n 462: 0.9989964679593859,\n 463: 0.9989963278990871,\n 464: 0.9989963278990871,\n 465: 0.9989964679593858,\n 466: 0.9989966080196846,\n 467: 0.9989964679593858,\n 468: 0.9989963278990871,\n 469: 0.9989964679593858,\n 470: 0.9989966080196846,\n 471: 0.9989966080196846,\n 472: 0.9989964679593858,\n 473: 0.9989964679593858,\n 474: 0.9989964679593858,\n 475: 0.9989964679593858,\n 476: 0.9989964679593858,\n 477: 0.9989966080196846,\n 478: 0.9989964679593858,\n 479: 0.9989966080196846,\n 480: 0.9989964679593859,\n 481: 0.9989963278990871,\n 482: 0.9989964679593859,\n 483: 0.9989964679593859,\n 484: 0.9989964679593859,\n 485: 0.9989966080196846,\n 486: 0.9989966080196846,\n 487: 0.9989967480799834,\n 488: 0.9989968881402821,\n 489: 0.9989968881402821,\n 490: 0.9989968881402821,\n 491: 0.9989968881402821,\n 492: 0.9989968881402821,\n 493: 0.9989968881402821,\n 494: 0.9989970282005809,\n 495: 0.9989968881402821,\n 496: 0.9989971682608797,\n 497: 0.9989971682608797,\n 498: 0.9989971682608797,\n 499: 0.9989971682608797}"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 0.9992980177826158)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_l = max(best_score, key=lambda x: best_score[x])\n",
    "max_l, best_score[max_l]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "(True, 0.9992980177826158, 0.999293255732458)"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = D1ffic00ltLinearRegression()\n",
    "model.fit_with_l2(X_train, y_train, L=2)\n",
    "y_pred = model.predict(X_test)\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "# custom_model.fit_with_l2(X_train, y_train, L=-14)\n",
    "roc_auc_score(y_test, y_pred) > roc_auc_score(y_test, y_pred2), \\\n",
    "roc_auc_score(y_test, y_pred), roc_auc_score(y_test, y_pred2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999901940595612"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9999901940595612"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def check(M):\n",
    "    if M > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "data_ = pd.read_csv(\"predict.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "data_test = data_.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "Ms = 3.86 * 10 ** 33\n",
    "data_test[\"temp\"] = data_test[\"B-V\"].apply(color_index)\n",
    "# data_test[\"R\"] = np.sqrt(data_test.Vmag) / np.power(data_test.temp / 5778, 2)\n",
    "# data_test[\"M\"] = data_test.Vmag + 5 - (5 * np.log(data_test.Plx))\n",
    "# data_test[\"L\"] = np.power(data_test.R, 2) * np.power(data_test.temp / 5778, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns) == list(data_test.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Vmag', 'Plx', 'e_Plx', 'B-V', 'SpType', 'Amag', 'TargetClass', 'temp'], dtype='object')"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Vmag', 'Plx', 'e_Plx', 'B-V', 'SpType', 'Amag', 'temp'], dtype='object')"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "       Vmag        Plx     e_Plx       B-V       SpType       Amag  \\\n0  4.039519  13.596504  0.845101 -0.097823      F5V+...  15.774122   \n1  6.655719   4.010332  1.050017  1.386670        K5III  15.344976   \n2  6.405060   0.348855  0.961598  0.951503       B0IVpe  12.236103   \n3  9.113068   2.954461  1.251422  1.002819        K1III  15.560838   \n4  6.107686   3.144180  0.475795  0.493345  G8II-IIIvar  12.771981   \n\n           temp  \n0  11536.343340  \n1   3972.332732  \n2   4862.277063  \n3   4735.981168  \n4   6419.225528  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vmag</th>\n      <th>Plx</th>\n      <th>e_Plx</th>\n      <th>B-V</th>\n      <th>SpType</th>\n      <th>Amag</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.039519</td>\n      <td>13.596504</td>\n      <td>0.845101</td>\n      <td>-0.097823</td>\n      <td>F5V+...</td>\n      <td>15.774122</td>\n      <td>11536.343340</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.655719</td>\n      <td>4.010332</td>\n      <td>1.050017</td>\n      <td>1.386670</td>\n      <td>K5III</td>\n      <td>15.344976</td>\n      <td>3972.332732</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.405060</td>\n      <td>0.348855</td>\n      <td>0.961598</td>\n      <td>0.951503</td>\n      <td>B0IVpe</td>\n      <td>12.236103</td>\n      <td>4862.277063</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.113068</td>\n      <td>2.954461</td>\n      <td>1.251422</td>\n      <td>1.002819</td>\n      <td>K1III</td>\n      <td>15.560838</td>\n      <td>4735.981168</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.107686</td>\n      <td>3.144180</td>\n      <td>0.475795</td>\n      <td>0.493345</td>\n      <td>G8II-IIIvar</td>\n      <td>12.771981</td>\n      <td>6419.225528</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "data_test.SpType = data_test.SpType.apply(transform_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "data_test[:] = MinMaxScaler().fit_transform(data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "pred = xgb.predict(data_test.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "# pred =[check(i) for i in data_test.M]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "data_[\"TargetClass\"] = pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "          Vmag        Plx     e_Plx       B-V       SpType       Amag  \\\n0     4.039519  13.596504  0.845101 -0.097823      F5V+...  15.774122   \n1     6.655719   4.010332  1.050017  1.386670        K5III  15.344976   \n2     6.405060   0.348855  0.961598  0.951503       B0IVpe  12.236103   \n3     9.113068   2.954461  1.251422  1.002819        K1III  15.560838   \n4     6.107686   3.144180  0.475795  0.493345  G8II-IIIvar  12.771981   \n...        ...        ...       ...       ...          ...        ...   \n7906  8.255272   2.858885  0.822289  1.349195        M3III  16.438014   \n7907  6.255358   3.034436  0.449386  0.966053        K0III  13.898403   \n7908  8.643598  10.932145  0.947897  0.504383          G0V  18.980729   \n7909  9.400810   6.279361  1.332124  0.351073          F2V  16.872491   \n7910  8.792551   2.379289  1.451311  1.110596        K1III  15.737505   \n\n      TargetClass  \n0        0.209362  \n1        0.069348  \n2        0.209282  \n3        0.069348  \n4        0.069348  \n...           ...  \n7906     0.069348  \n7907     0.069348  \n7908     0.209282  \n7909     0.209282  \n7910     0.069348  \n\n[7911 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vmag</th>\n      <th>Plx</th>\n      <th>e_Plx</th>\n      <th>B-V</th>\n      <th>SpType</th>\n      <th>Amag</th>\n      <th>TargetClass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.039519</td>\n      <td>13.596504</td>\n      <td>0.845101</td>\n      <td>-0.097823</td>\n      <td>F5V+...</td>\n      <td>15.774122</td>\n      <td>0.209362</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.655719</td>\n      <td>4.010332</td>\n      <td>1.050017</td>\n      <td>1.386670</td>\n      <td>K5III</td>\n      <td>15.344976</td>\n      <td>0.069348</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.405060</td>\n      <td>0.348855</td>\n      <td>0.961598</td>\n      <td>0.951503</td>\n      <td>B0IVpe</td>\n      <td>12.236103</td>\n      <td>0.209282</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.113068</td>\n      <td>2.954461</td>\n      <td>1.251422</td>\n      <td>1.002819</td>\n      <td>K1III</td>\n      <td>15.560838</td>\n      <td>0.069348</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.107686</td>\n      <td>3.144180</td>\n      <td>0.475795</td>\n      <td>0.493345</td>\n      <td>G8II-IIIvar</td>\n      <td>12.771981</td>\n      <td>0.069348</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7906</th>\n      <td>8.255272</td>\n      <td>2.858885</td>\n      <td>0.822289</td>\n      <td>1.349195</td>\n      <td>M3III</td>\n      <td>16.438014</td>\n      <td>0.069348</td>\n    </tr>\n    <tr>\n      <th>7907</th>\n      <td>6.255358</td>\n      <td>3.034436</td>\n      <td>0.449386</td>\n      <td>0.966053</td>\n      <td>K0III</td>\n      <td>13.898403</td>\n      <td>0.069348</td>\n    </tr>\n    <tr>\n      <th>7908</th>\n      <td>8.643598</td>\n      <td>10.932145</td>\n      <td>0.947897</td>\n      <td>0.504383</td>\n      <td>G0V</td>\n      <td>18.980729</td>\n      <td>0.209282</td>\n    </tr>\n    <tr>\n      <th>7909</th>\n      <td>9.400810</td>\n      <td>6.279361</td>\n      <td>1.332124</td>\n      <td>0.351073</td>\n      <td>F2V</td>\n      <td>16.872491</td>\n      <td>0.209282</td>\n    </tr>\n    <tr>\n      <th>7910</th>\n      <td>8.792551</td>\n      <td>2.379289</td>\n      <td>1.451311</td>\n      <td>1.110596</td>\n      <td>K1III</td>\n      <td>15.737505</td>\n      <td>0.069348</td>\n    </tr>\n  </tbody>\n</table>\n<p>7911 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "data_.to_csv(\"answer.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}